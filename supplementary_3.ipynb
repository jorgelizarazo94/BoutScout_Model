{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<img src=\"assets/logo.png\" width=\"300px\">\n",
    "\n",
    "# Supplementary 3 - Final Model Training and Export\n",
    "**BoutScout: A Deep Learning Framework for Automatic Detection of Incubation Events in Avian Nests Using Temperature Time Series**\n",
    "\n",
    "Author: [Jorge Lizarazo](https://www.researchgate.net/profile/Jorge-Lizarazo-Borrero?ev=hdr_xprf)\n",
    "\n",
    "This notebook describes the training of the final production-ready BiLSTM model using the complete cleaned dataset (2,232 nest-days). We apply class-balanced weights to address label imbalance and track training loss over 80 epochs. The trained model is saved in both PyTorch (`.pth`) and ONNX formats, enabling deployment in diverse environments. Additionally, we extract hidden representations from the LSTM layers and visualize them using t-SNE, providing insight into class separation in latent space. This version of the model is designed to support fast and reproducible inference across a variety of applications.\n",
    "\n",
    "\n",
    "**Year:** 2025"
   ],
   "id": "2b1f7af5cf129675"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:20.406750Z",
     "start_time": "2025-06-15T05:13:20.307496Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:32.267469Z",
     "start_time": "2025-06-15T05:13:30.699472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kargar arrays\n",
    "X_array = np.load(\"X_array_cleaned.npy\", allow_pickle=True)\n",
    "y_array = np.load(\"y_array_cleaned.npy\", allow_pickle=True)\n",
    "\n",
    "# Kargar clases del LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "\n",
    "# Definir Dataset\n",
    "class NestEventDataset(Dataset):\n",
    "    def __init__(self, X_array, y_array):\n",
    "        self.X_array = X_array\n",
    "        self.y_array = y_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X_array[idx].astype(np.float32)\n",
    "        y = self.y_array[idx].astype(np.int64)\n",
    "        return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "# Crear el dataset\n",
    "dataset = NestEventDataset(X_array, y_array)"
   ],
   "id": "ae0e5bdee178a9c6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:34.298643Z",
     "start_time": "2025-06-15T05:13:34.264206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx = random.randint(0, len(dataset) - 1)\n",
    "X_sample, y_sample = dataset[idx]\n",
    "X_np = X_sample.numpy()\n",
    "y_np = y_sample.numpy()"
   ],
   "id": "d4acddd554915ff5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:35.774544Z",
     "start_time": "2025-06-15T05:13:35.738779Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Numero total de dias (entradas): {len(y_array)}\")",
   "id": "bb0de3dde3e0294c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de dias (entradas): 2232\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:37.452885Z",
     "start_time": "2025-06-15T05:13:37.414264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx = random.randint(0, len(X_array) - 1)\n",
    "X_sample = X_array[idx].astype(np.float32)\n",
    "y_sample = y_array[idx].astype(np.int64)\n",
    "\n",
    "X_np = X_sample\n",
    "y_np = y_sample"
   ],
   "id": "512c8b29c222397a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:39.333946Z",
     "start_time": "2025-06-15T05:13:39.299719Z"
    }
   },
   "cell_type": "code",
   "source": "y_np",
   "id": "d88377bb75107363",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:40.712694Z",
     "start_time": "2025-06-15T05:13:40.694671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ],
   "id": "2ca3e3c298787870",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:42.791072Z",
     "start_time": "2025-06-15T05:13:42.775154Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7bcbc39179b9c22f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:44.104080Z",
     "start_time": "2025-06-15T05:13:44.069547Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
   "id": "f237118f483651c4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "29e644d36ee23018"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "We create folders to store the trained model, weight matrices, and t-SNE results. Also initialized the final DataLoader using the full dataset for training."
   ],
   "id": "3cad91f854b2a2fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:46.562054Z",
     "start_time": "2025-06-15T05:13:46.538297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Crear carpeta si no existe\n",
    "os.makedirs(\"modelo_fi_total\", exist_ok=True)\n",
    "os.makedirs(\"modelo_fi_total/weights\", exist_ok=True)\n",
    "os.makedirs(\"modelo_fi_total/tsne\", exist_ok=True)"
   ],
   "id": "af3baf4a415e194f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:48.027781Z",
     "start_time": "2025-06-15T05:13:48.002307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_dataset = NestEventDataset(X_array, y_array)\n",
    "final_loader = DataLoader(final_dataset, batch_size=16, shuffle=True)"
   ],
   "id": "9a82cb1a57b2b9d3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:13:51.230607Z",
     "start_time": "2025-06-15T05:13:49.405110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.manifold import TSNE"
   ],
   "id": "b2fc817d3191486c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final model setup with class-weighted loss\n",
    "We define the final BiLSTM model and apply class weighting to address label imbalance.\n",
    "Weights are automatically computed and manually adjusted to penalize misclassification of `Off` and `On` bouts more heavily. The weighted loss function helps the model learn from underrepresented transitions, improving overall class balance during training."
   ],
   "id": "903d54eaed5726e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T05:14:02.291619Z",
     "start_time": "2025-06-15T05:13:53.502204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modelo_final = BiLSTMModel(\n",
    "    input_size=X_array[0].shape[1],\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    num_classes=3\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(modelo_final.parameters(), lr=0.001)\n",
    "y_array_flat = np.concatenate(y_array).ravel()\n",
    "\n",
    "# Kalklar pesos balansiados otomatikos\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_array_flat), y=y_array_flat)\n",
    "\n",
    "#\n",
    "class_weights[1] *= 2.5  # kastigo adisional a Off\n",
    "class_weights[2] *= 3.0  # kastigo mas fuerte a On\n",
    "\n",
    "# Trokar a tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# verifikar\n",
    "print(\"Pesos finales usados para la pérdida:\", class_weights)\n",
    "\n",
    "# Funsion de perdida ponderada\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "num_epochs = 80\n",
    "\n",
    "modelo_final.train()\n",
    "losses = []\n"
   ],
   "id": "e76066f27a6b8a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos finales usados para la pérdida: [0.67203107 4.40714054 3.17556986]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Final model training, export, and latent space analysis\n",
    "We train the final version of the BiLSTM model for 80 epochs using the full dataset, applying the class-weighted loss function to improve sensitivity to `Off` and `On` transitions. Training loss is recorded at each epoch to monitor convergence.\n",
    "\n",
    "After training, we:\n",
    "1. Save the final model weights in PyTorch format (`.pth`).\n",
    "2. Export the loss curve as a NumPy array for later visualization.\n",
    "3. Extract and save learned weight matrices from each LSTM layer.\n",
    "4. Export the model in ONNX format for deployment in non-PyTorch environments.\n",
    "\n",
    "To explore how the model organizes behavior patterns internally, there was extracted the average hidden representation per sequence and apply t-SNE dimensionality reduction, and yet it was not taken into consideration for the manuscript. This allows us to visualize the latent structure of the learned embedding space and assess class separation. All results are saved in the `modelo_fi_total/` folder."
   ],
   "id": "ae124e5d8c8d783b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in final_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = modelo_final(X_batch)\n",
    "        loss = criterion(outputs.view(-1, outputs.shape[-1]), y_batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(final_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# === Asentar rezultados ===\n",
    "\n",
    "# 1. modelo ambezado\n",
    "torch.save(modelo_final.state_dict(), \"modelo_fi_total/modelo_entrenado_final_total.pth\")\n",
    "\n",
    "# 2. kurva de desaparesimiento\n",
    "np.save(\"modelo_fi_total/training_loss.npy\", np.array(losses))\n",
    "\n",
    "# 3. pesos por estrato\n",
    "for name, param in modelo_final.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        np.save(f\"modelo_fi_total/weights/{name}.npy\", param.detach().cpu().numpy())\n",
    "\n",
    "# 4. Eksportar modelo en formato ONNX\n",
    "dummy_input = torch.randn(1, X_array[0].shape[0], X_array[0].shape[1]).to(device)\n",
    "torch.onnx.export(\n",
    "    modelo_final, dummy_input,\n",
    "    \"modelo_fi_total/onnx_model.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "# Sakar i asentar lugar escondido kon t-SNE\n",
    "modelo_final.eval()\n",
    "X_latentes = []\n",
    "y_latentes = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in final_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        lstm_output, _ = modelo_final.lstm(X_batch)\n",
    "        avg_output = lstm_output.mean(dim=1)  # (batch, hidden)\n",
    "        X_latentes.append(avg_output.cpu().numpy())\n",
    "        y_latentes.append(y_batch.cpu().numpy())\n",
    "\n",
    "X_latentes = np.vstack(X_latentes)\n",
    "y_latentes = np.concatenate(y_latentes)\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_latentes)\n",
    "\n",
    "# Guardar t-SNE\n",
    "np.save(\"modelo_fi_total/tsne/X_tsne.npy\", X_tsne)\n",
    "np.save(\"modelo_fi_total/tsne/y_tsne.npy\", y_latentes)\n",
    "\n",
    "print(\"✅ donde mate go to 'modelo_fi_total/'\")"
   ],
   "id": "c604f187d9c69296"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Final training loss curve\n",
    "We plot the training loss over 80 epochs to confirm model convergence.\n"
   ],
   "id": "1bc99e7fc77f9612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Yevár la línea de desaparesimiento\n",
    "losses = np.load(\"modelo_fi_total/training_loss.npy\")\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(losses, label=\"Training Loss\", color=\"#707070\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.ylim(0, 1.0)  # Asentar kon números verdaderos\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig(\"figures/training_loss_plot.png\", dpi=300)\n",
    "plt.show()"
   ],
   "id": "61da5b44ca620243"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Export model with batch size = 1 (ONNX) as a backup\n",
    "As a backup we reshaped the input into a 3D tensor and export the final model to ONNX format with dynamic batch size set to 1, ensuring compatibility for real-time inference scenarios."
   ],
   "id": "69f049d5e09508b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Revisar una muestra para asigurárse de la armadura\n",
    "print(\"Ejemplo de un elemento:\", type(X_array[0]), X_array[0].shape)\n",
    "\n",
    "# Unifikar todos los arreglos en una kaxa 3D\n",
    "X_array = np.stack(X_array)  # (2232, seq_len, n_features)\n",
    "\n",
    "# Asentár el kambio de formato\n",
    "print(\"Nueva forma de X_array:\", X_array.shape)"
   ],
   "id": "75c4e6584e6ec7eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "seq_len = X_array.shape[1]\n",
    "n_features = X_array.shape[2]\n",
    "\n",
    "dummy_input = torch.randn(1, seq_len, n_features).to(device)"
   ],
   "id": "3db6ac8ae726c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "modelo_final.eval()\n",
    "\n",
    "# krear dummy input kon batch size = 1\n",
    "seq_len = X_array.shape[1]\n",
    "n_features = X_array.shape[2]\n",
    "dummy_input = torch.randn(1, seq_len, n_features).to(device)\n",
    "\n",
    "# ONNX\n",
    "torch.onnx.export(\n",
    "    modelo_final, dummy_input,\n",
    "    \"modelo_fi_total/onnx_model_batch1.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "print(\"✅ Modelo exportado a 'modelo_fi_total/onnx_model_batch1.onnx'\")"
   ],
   "id": "4816b8bf6d7a8011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(type(X_array))\n",
    "print(X_array.shape if hasattr(X_array, 'shape') else \"No tiene atributo shape\")"
   ],
   "id": "b1aa008559551205"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
